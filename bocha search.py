import json
import time
import requests
import trafilatura
from openai import OpenAI

# ================= é…ç½®åŒº =================

# 1. LLM é…ç½® (ä¿æŒä¸å˜)
LLM_API_KEY = ""
BASE_URL = ""
MODEL_NAME = ""

# 2. Bocha (åšæŸ¥) é…ç½®
# ï¼ï¼ï¼è¯·åœ¨æ­¤å¤„å¡«å…¥æ‚¨çš„åšæŸ¥ API Key ï¼ï¼ï¼
BOCHA_API_KEY = ""

# 3. çˆ¬è™«ä¼ªè£…å¤´
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}

client = OpenAI(api_key=LLM_API_KEY, base_url=BASE_URL)


# ================= ç¬¬ä¸€éƒ¨åˆ†ï¼šåšæŸ¥æœç´¢ä¸å†…å®¹è·å–å·¥å…· =================

def bocha_search(query, count=3):
    """
    è°ƒç”¨åšæŸ¥ Web Search API
    æ–‡æ¡£å‚è€ƒ: https://bocha-ai.feishu.cn/wiki/RXEOw02rFiwzGSkd9mUcqoeAnNK
    """
    print(f"   [æ­£åœ¨æœç´¢(Bocha)]: {query}")

    url = "https://api.bochaai.com/v1/web-search"

    headers = {
        "Authorization": f"Bearer {BOCHA_API_KEY}",
        "Content-Type": "application/json"
    }

    # æ„é€ è¯·æ±‚ä½“
    payload = {
        "query": query,
        "count": count,
        "summary": True,  # è¯·æ±‚é•¿æ‘˜è¦ï¼Œç¡®ä¿ä¿¡æ¯é‡
        "freshness": "noLimit"  # ä¸é™åˆ¶æ—¶é—´ï¼Œå¦‚æœæ˜¯æ–°é—»ç±»å¯æ”¹ä¸º oneDay/oneWeek
    }

    try:
        resp = requests.post(url, headers=headers, json=payload, timeout=15)
        if resp.status_code == 200:
            data = resp.json()
            # å…¼å®¹åšæŸ¥è¿”å›ç»“æ„: data -> webPages -> value
            if "data" in data and "webPages" in data["data"]:
                return data["data"]["webPages"]["value"]
            else:
                print(f"   åšæŸ¥è¿”å›æ•°æ®ä¸ºç©ºæˆ–æ ¼å¼å¼‚å¸¸: {data}")
                return []
        else:
            print(f"   åšæŸ¥æ¥å£æŠ¥é”™: {resp.status_code} - {resp.text}")
            return []
    except Exception as e:
        print(f"   æœç´¢è¯·æ±‚å¼‚å¸¸: {e}")
        return []


def get_page_content(url):
    """
    å°è¯•æŠ“å–ç½‘é¡µå…¨æ–‡ã€‚
    å¦‚æœ trafilatura æŠ“å–å¤±è´¥ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œäº¤ç”±ä¸Šå±‚é€»è¾‘ä½¿ç”¨åšæŸ¥æ‘˜è¦å…œåº•ã€‚
    """
    try:
        # 1. å°è¯• trafilatura ç›´æ¥ä¸‹è½½
        downloaded = trafilatura.fetch_url(url)

        # 2. å¦‚æœ trafilatura ä¸‹è½½å¤±è´¥ï¼Œå°è¯• requests è¡¥æ•‘
        if not downloaded:
            resp = requests.get(url, headers=HEADERS, timeout=10)
            if resp.status_code == 200:
                resp.encoding = resp.apparent_encoding
                downloaded = resp.text
            else:
                return ""

        # 3. æå–æ­£æ–‡
        if downloaded:
            text = trafilatura.extract(downloaded, include_comments=False, target_language='zh')
            if text:
                # æˆªå–å‰ 3000 å­—ç¬¦ï¼Œé˜²æ­¢ Token æº¢å‡ºï¼ŒåŒæ—¶ä¿è¯ä¸»è¦å†…å®¹è¢«è¯»å–
                return text[:3000].replace("\n", " ")

        return ""
    except Exception:
        return ""


def search_tool(query):
    """
    Agent è°ƒç”¨çš„æ ¸å¿ƒå·¥å…·ï¼š
    1. ä½¿ç”¨åšæŸ¥æœç´¢
    2. éå†ç»“æœï¼Œå°è¯•çˆ¬å–å…¨æ–‡
    3. å¦‚æœçˆ¬ä¸åˆ°å…¨æ–‡ï¼Œä½¿ç”¨åšæŸ¥æä¾›çš„ Summary
    """
    # æœç´¢å‰3æ¡ï¼Œä¿è¯é€Ÿåº¦å’Œç›¸å…³æ€§
    items = bocha_search(query, count=3)

    if not items:
        return "ã€ç³»ç»Ÿæç¤ºã€‘ï¼šæœªæ‰¾åˆ°ä»»ä½•æœç´¢ç»“æœï¼Œè¯·å°è¯•æ›´æ¢å…³é”®è¯ã€‚"

    report = f"é’ˆå¯¹æŸ¥è¯¢ '{query}' çš„æœç´¢ç»“æœï¼š\n"

    for i, item in enumerate(items):
        # åšæŸ¥çš„å­—æ®µé€šå¸¸æ˜¯ name(æ ‡é¢˜), url(é“¾æ¥), summary(æ‘˜è¦), snippet(ç‰‡æ®µ)
        title = item.get('name', 'æ— æ ‡é¢˜')
        link = item.get('url', '')
        # ä¼˜å…ˆå– summary (é•¿æ‘˜è¦)ï¼Œæ²¡æœ‰åˆ™å– snippet
        bocha_summary = item.get('summary', '') or item.get('snippet', '')

        # --- æ ¸å¿ƒé€»è¾‘ï¼šè·å–å®Œæ•´å†…å®¹ ---
        # å°è¯•è®¿é—®é“¾æ¥è·å–å…¨æ–‡
        full_text = get_page_content(link)

        # å†³ç­–ï¼šå¦‚æœæŠ“åˆ°äº†å…¨æ–‡ä¸”é•¿åº¦è¶³å¤Ÿï¼Œç”¨å…¨æ–‡ï¼›å¦åˆ™ç”¨åšæŸ¥çš„æ‘˜è¦
        if len(full_text) > 100:
            content = f"ã€ç½‘é¡µå…¨æ–‡æå–ã€‘: {full_text}"
        else:
            content = f"ã€åšæŸ¥æ‘˜è¦(ç½‘é¡µä¸å¯çˆ¬)ã€‘: {bocha_summary}"

        report += f"--- æ¥æº {i + 1}: {title} ---\n"
        report += f"é“¾æ¥: {link}\n"
        report += f"å†…å®¹: {content}\n\n"

    return report


# ================= ç¬¬äºŒéƒ¨åˆ†ï¼šReAct Agent é€»è¾‘ (ä¿æŒé€»è¾‘ä¸¥å¯†æ€§) =================

def run_agent(question, max_steps=10):
    print("=" * 60)
    print(f"Agent å¯åŠ¨ | ç›®æ ‡é—®é¢˜: {question}")
    print("=" * 60)

    # Prompt ä¿æŒä¸å˜ï¼Œå¼ºè°ƒé€»è¾‘æ¨ç†
    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªå…·å¤‡æ·±åº¦è”ç½‘æœç´¢èƒ½åŠ›çš„æ™ºèƒ½åŠ©æ‰‹ã€‚
    å½“ä»Šæ˜¯202
    ä½ çš„ä»»åŠ¡æ˜¯é€šè¿‡åˆ†æ­¥éª¤çš„æœç´¢æ¥è§£å†³å¤æ‚é—®é¢˜ã€‚

    ã€å·¥ä½œæµã€‘ï¼š
    1. åˆ†æç”¨æˆ·é—®é¢˜ï¼Œå†³å®šæœç´¢ä»€ä¹ˆå…³é”®è¯ã€‚
    2. è§‚å¯Ÿæœç´¢ç»“æœï¼ˆæˆ‘ä¼šæä¾›ç½‘é¡µå…¨æ–‡æˆ–é•¿æ‘˜è¦ï¼‰ã€‚
    3. æ ¹æ®ç»“æœå†³å®šæ˜¯ç»§ç»­æœç´¢æ–°ä¿¡æ¯ï¼Œè¿˜æ˜¯è¿›è¡Œæ€»ç»“å›ç­”ã€‚

    ã€è¾“å‡ºæ ¼å¼(ä¸¥æ ¼JSON)ã€‘ï¼š
    {
        "thought": "æ€è€ƒè¿‡ç¨‹ï¼šåˆ†æå½“å‰è·å–åˆ°äº†ä»€ä¹ˆï¼Œè¿˜éœ€è¦ä»€ä¹ˆ",
        "action": "search" æˆ– "finish",
        "query": "æœç´¢å…³é”®è¯(ä»…å½“actionä¸ºsearchæ—¶)",
        "answer": "æœ€ç»ˆç­”æ¡ˆ(ä»…å½“actionä¸ºfinishæ—¶ï¼Œéœ€è¯¦å°½å¹¶å¼•ç”¨æ•°æ®)"
    }
    """

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"è¯·è§£å†³è¿™ä¸ªé—®é¢˜ï¼š{question}"}
    ]

    step = 0
    while step < max_steps:
        step += 1
        print(f"\nâš¡ [Step {step}]: æ€è€ƒä¸­...")

        # 1. LLM å†³ç­–
        try:
            response = client.chat.completions.create(
                model=MODEL_NAME,
                messages=messages,
                temperature=0.3,
                response_format={"type": "json_object"},
                max_tokens=1000
            )
            content = response.choices[0].message.content

            # æ¸…æ´—å¯èƒ½å­˜åœ¨çš„ Markdown ç¬¦å·
            content_clean = content.replace("```json", "").replace("```", "").strip()
            decision = json.loads(content_clean)

        except Exception as e:
            print(f"   JSONè§£æå¤±è´¥ï¼Œé‡è¯•... {e}")
            continue

        thought = decision.get("thought", "")
        action = decision.get("action", "")
        print(f"   [æ€ç»´é“¾]: {thought}")

        # 2. æ‰§è¡ŒåŠ¨ä½œ
        if action == "search":
            query = decision.get("query")
            if not query:
                print("   [è­¦å‘Š] æ¨¡å‹æœªç”ŸæˆæŸ¥è¯¢è¯")
                continue

            # è°ƒç”¨åšæŸ¥æœç´¢å·¥å…·
            tool_output = search_tool(query)

            # å†™å…¥å†å²
            messages.append({"role": "assistant", "content": content})
            messages.append({"role": "user", "content": f"ã€æœç´¢å·¥å…·è¿”å›æ•°æ®ã€‘:\n{tool_output}"})

        elif action == "finish":
            final_answer = decision.get("answer")
            print("\n" + "=" * 30 + " ğŸ æœ€ç»ˆç»“è®º " + "=" * 30)
            print(final_answer)
            return final_answer

        else:
            print(f"   æœªçŸ¥åŠ¨ä½œ: {action}")
            break

    print("\nä»»åŠ¡è¾¾åˆ°æœ€å¤§æ­¥æ•°åœæ­¢ã€‚")


if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šæ±‡ç‡æŸ¥è¯¢åŠåˆ†æ
    # åšæŸ¥èƒ½å¾ˆå¥½åœ°æ£€ç´¢åˆ°å®æ—¶æ•°æ®å’Œæ–°é—»åˆ†æ
    complex_question = "è¯„ä»·ä¸€ä¸‹æ˜Ÿé™…äº‰éœ¸2ä¸­ä¸‰ä¸ªç§æ—å¼ºåº¦"

    if "YOUR_BOCHA_API_KEY" in BOCHA_API_KEY:
        print("âŒ é”™è¯¯ï¼šè¯·å…ˆåœ¨ä»£ç ç¬¬ 16 è¡Œå¡«å…¥ä½ çš„åšæŸ¥ API Key")
    else:
        run_agent(complex_question)