import streamlit as st
import json
import requests
import trafilatura
from openai import OpenAI
from duckduckgo_search import DDGS
import datetime

# ================= [é¡µé¢å…¨å±€é…ç½®] =================
st.set_page_config(
    page_title="AI æ·±åº¦ç ”ç©¶å‘˜",
    page_icon="ğŸ•µï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ğŸ•µï¸ AI æ·±åº¦è”ç½‘æœç´¢åŠ©æ‰‹ (Deep Research)")
st.markdown("---")

# ================= [ä¾§è¾¹æ é…ç½®åŒº] =================
with st.sidebar:
    st.header("âš™ï¸ å‚æ•°é…ç½®")

    # æœç´¢æºé€‰æ‹©
    search_source_option = st.selectbox(
        "é€‰æ‹©æœç´¢æº",
        options=[1, 2, 3],
        format_func=lambda x: {
            1: "1. Bocha (åšæŸ¥ - æ¨è)",
            2: "2. Google Custom Search",
            3: "3. DuckDuckGo (æ— éœ€Key+ä»£ç†)"
        }[x],
        index=2  # é»˜è®¤ DDG
    )

    # API Keys é…ç½®
    with st.expander("ğŸ”‘ API Key è®¾ç½®", expanded=True):
        silicon_key = st.text_input("SiliconFlow API Key", value="",
                                    type="password")
        bocha_key = st.text_input("Bocha API Key", value="", type="password")
        google_key = st.text_input("Google API Key", value="", type="password")
        google_cx = st.text_input("Google CX ID", value="")

    # ç½‘ç»œä¸æ¨¡å‹é…ç½®
    with st.expander("ğŸŒ ç½‘ç»œä¸æ¨¡å‹", expanded=False):
        # é»˜è®¤ä»£ç†ç•™ç©ºï¼Œæ ¹æ®è‡ªå·±æƒ…å†µå¡«ï¼Œå¦‚ http://127.0.0.1:7890
        proxy_url = st.text_input("HTTP Proxy (å¦‚éœ€è¦)", value="http://127.0.0.1:7890")
        model_name = st.text_input("æ¨¡å‹åç§°", value="Qwen/Qwen3-235B-A22B-Instruct-2507")
        base_url = st.text_input("Base URL", value="https://api.siliconflow.cn/v1")

        max_steps = st.slider("æœ€å¤§æ€è€ƒæ­¥æ•°", 3, 15, 8)

# ================= [æ ¸å¿ƒå·¥å…·å‡½æ•°] =================

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}
BLACKLIST = ["baidu.com", "zhihu.com", "tieba.baidu.com", "csdn.net"]

# å¿½ç•¥ SSL è­¦å‘Š
requests.packages.urllib3.disable_warnings()


def get_page_content(url, proxy):
    """é€šç”¨ç½‘é¡µæŠ“å–å·¥å…·"""
    try:
        proxies = {"http": proxy, "https": proxy} if proxy else None

        # 1. å°è¯• trafilatura ç›´æ¥ä¸‹è½½ (é€Ÿåº¦å¿«)
        if not proxy:
            downloaded = trafilatura.fetch_url(url)
            if downloaded:
                text = trafilatura.extract(downloaded, include_comments=False, target_language='zh')
                if text: return text[:5000].replace("\n", " ")

        # 2. Requests å›é€€æœºåˆ¶ (æ”¯æŒä»£ç†)
        verify_ssl = not bool(proxy)
        resp = requests.get(url, headers=HEADERS, proxies=proxies, timeout=10, verify=verify_ssl)

        if resp.status_code == 200:
            resp.encoding = resp.apparent_encoding
            text = trafilatura.extract(resp.text, include_comments=False, target_language='zh')
            if text:
                return text[:5000].replace("\n", " ")
            return ""
        return ""
    except Exception:
        return ""


# --- æœç´¢å®ç° ---
def search_bocha(query, api_key):
    if not api_key: return "âŒ é”™è¯¯ï¼šæœªå¡«å†™ Bocha API Key"
    url = "https://api.bochaai.com/v1/web-search"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {"query": query, "count": 3, "summary": True, "freshness": "noLimit"}

    try:
        resp = requests.post(url, headers=headers, json=payload, timeout=15)
        if resp.status_code == 200:
            data = resp.json()
            if "data" in data and "webPages" in data["data"]:
                items = data["data"]["webPages"]["value"]
                report = f"é’ˆå¯¹æŸ¥è¯¢ '{query}' çš„ Bocha ç»“æœï¼š\n"
                for i, item in enumerate(items):
                    link = item.get('url', '')
                    summary = item.get('summary', '') or item.get('snippet', '')
                    # çˆ¬å–æ­£æ–‡
                    full_text = get_page_content(link, None)
                    content = full_text if len(full_text) > 200 else f"ã€æ‘˜è¦ã€‘{summary}"
                    report += f"--- æ¥æº {i + 1}: {item.get('name')} ---\né“¾æ¥: {link}\nå†…å®¹: {content}\n\n"
                return report
        return "Bocha æœªè¿”å›æœ‰æ•ˆç»“æœã€‚"
    except Exception as e:
        return f"Bocha æ¥å£å¼‚å¸¸: {e}"


def search_google(query, api_key, cx_id):
    if not api_key or not cx_id: return "âŒ é”™è¯¯ï¼šæœªå¡«å†™ Google API Key æˆ– CX ID"
    url = "https://www.googleapis.com/customsearch/v1"
    params = {'q': query, 'key': api_key, 'cx': cx_id, 'num': 3}

    try:
        resp = requests.get(url, params=params, timeout=15)
        if resp.status_code == 200:
            items = resp.json().get('items', [])
            if not items: return "Google æœªæ‰¾åˆ°ç»“æœã€‚"

            report = f"é’ˆå¯¹æŸ¥è¯¢ '{query}' çš„ Google ç»“æœï¼š\n"
            for i, item in enumerate(items):
                link = item.get('link', '')
                snippet = item.get('snippet', '')
                full_text = get_page_content(link, None)
                content = full_text if len(full_text) > 200 else f"ã€æ‘˜è¦ã€‘{snippet}"
                report += f"--- æ¥æº {i + 1}: {item.get('title')} ---\né“¾æ¥: {link}\nå†…å®¹: {content}\n\n"
            return report
        return f"Google æ¥å£æŠ¥é”™: {resp.status_code}"
    except Exception as e:
        return f"Google è¯·æ±‚å¼‚å¸¸: {e}"


def search_ddg(query, proxy):
    try:
        results = []
        with DDGS(proxy=proxy, timeout=30) as ddgs:
            results = list(ddgs.text(keywords=query, region='wt-wt', max_results=10, backend="html"))

        if not results: return "DuckDuckGo æœªæ‰¾åˆ°ç»“æœã€‚"

        report = f"é’ˆå¯¹æŸ¥è¯¢ '{query}' çš„ DDG ç»“æœï¼š\n"
        valid_count = 0

        for item in results:
            if valid_count >= 3: break
            link = item.get('href', '')
            title = item.get('title', '')
            snippet = item.get('body', '')

            # ç®€å•çš„é»‘åå•è¿‡æ»¤
            if any(domain in link for domain in BLACKLIST): continue

            valid_count += 1
            full_text = get_page_content(link, proxy)
            content = full_text if len(full_text) > 500 else f"ã€æ‘˜è¦ã€‘{snippet}"
            report += f"--- æ¥æº {valid_count}: {title} ---\né“¾æ¥: {link}\nå†…å®¹: {content}\n\n"

        return report if valid_count > 0 else "ç»“æœå‡åœ¨é»‘åå•ä¸­ã€‚"
    except Exception as e:
        return f"DuckDuckGo è¿æ¥å¤±è´¥: {e}"


def unified_search(query, source, bocha_key, google_key, google_cx, proxy):
    """ç»Ÿä¸€æœç´¢è°ƒåº¦å…¥å£"""
    if source == 1:
        return search_bocha(query, bocha_key)
    elif source == 2:
        return search_google(query, google_key, google_cx)
    elif source == 3:
        return search_ddg(query, proxy)
    return "æ— æ•ˆçš„æœç´¢æº"


# ================= [æ ¸å¿ƒï¼šAgent é€»è¾‘ (ç”Ÿæˆå™¨)] =================

def run_agent_generator(question, api_key, base_url, model, source, bocha_k, google_k, google_c, proxy, max_steps):
    """
    Agent ä¸»é€»è¾‘ï¼šé€šè¿‡ yield è¿”å›æµå¼çŠ¶æ€æ›´æ–°
    """
    client = OpenAI(api_key=api_key, base_url=base_url)
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    source_name = {1: "Bocha", 2: "Google", 3: "DuckDuckGo"}.get(source, "Unknown")

    # ğŸ”¥ æ·±åº¦æ€è€ƒçš„ System Prompt
    system_prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªå…·å¤‡æ·±åº¦è”ç½‘æœç´¢èƒ½åŠ›çš„æ™ºèƒ½ç ”ç©¶å‘˜ï¼Œå½“å‰æœç´¢å¼•æ“ï¼š{source_name}ã€‚
    å½“å‰æ—¶é—´ï¼š{now}

    ã€æ€ç»´æ¨¡å¼ã€‘ï¼š
    ä½ å¿…é¡»å±•ç°å‡ºæ˜¾å¼çš„â€œæ€ç»´é“¾ (Chain of Thought)â€ã€‚åœ¨æ‰§è¡Œä»»ä½•æ“ä½œå‰ï¼Œå…ˆè¿›è¡Œæ·±åº¦çš„é€»è¾‘åˆ†æã€‚

    ã€æ€è€ƒç»“æ„ã€‘ï¼š
    ä½ çš„ `thought` å­—æ®µå¿…é¡»åŒ…å«ä»¥ä¸‹æ®µè½ï¼ˆç”¨æ¢è¡Œåˆ†éš”ï¼‰ï¼š
    1. **[åˆ†æ]**ï¼šå½“å‰å·²çŸ¥ä»€ä¹ˆï¼Ÿè¿˜éœ€è¦æŸ¥ä»€ä¹ˆï¼Ÿ
    2. **[è¯„ä¼°]**ï¼šä¹‹å‰çš„æœç´¢ç»“æœå¯ä¿¡å—ï¼Ÿæ˜¯å¦æœ‰çŸ›ç›¾ï¼Ÿ
    3. **[å†³ç­–]**ï¼šä¸‹ä¸€æ­¥å…·ä½“åšä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ

    ã€è¾“å‡ºæ ¼å¼ (ä¸¥æ ¼ JSON)ã€‘ï¼š
    {{
        "thought": "ä½ çš„ç»“æ„åŒ–æ€è€ƒè¿‡ç¨‹...",
        "action": "search" æˆ– "finish",
        "query": "æœç´¢å…³é”®è¯ (ä»…å½“ action=search æ—¶ï¼Œå…³é”®è¯è¦å…·ä½“)",
        "answer": "æœ€ç»ˆç­”æ¡ˆ (ä»…å½“ action=finish æ—¶ï¼Œéœ€è¯¦å°½ã€ç»“æ„åŒ–å¹¶å¼•ç”¨æ¥æº)"
    }}
    """

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"è¯·è§£å†³è¿™ä¸ªé—®é¢˜ï¼š{question}"}
    ]

    step = 0
    while step < max_steps:
        step += 1
        yield {"type": "status_update", "content": f"âš¡ æ­£åœ¨è¿›è¡Œç¬¬ {step} æ­¥æ·±åº¦æ¨ç†..."}

        try:
            # è°ƒç”¨å¤§æ¨¡å‹
            response = client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=0.3,  # è¾ƒä½æ¸©åº¦ä¿æŒé€»è¾‘ä¸¥å¯†
                response_format={"type": "json_object"},
                max_tokens=2000  # å…è®¸é•¿æ€è€ƒ
            )
            content = response.choices[0].message.content
            # æ¸…æ´—å¯èƒ½å­˜åœ¨çš„ markdown æ ‡è®°
            content_clean = content.replace("```json", "").replace("```", "").strip()
            decision = json.loads(content_clean)
        except Exception as e:
            yield {"type": "error", "content": f"âŒ æ¨¡å‹è°ƒç”¨æˆ–JSONè§£æå¤±è´¥: {e}"}
            return

        thought = decision.get("thought", "ï¼ˆæœªè¿”å›æ€è€ƒè¿‡ç¨‹ï¼‰")
        action = decision.get("action", "")

        # 1. æ¨é€æ€è€ƒè¿‡ç¨‹
        yield {"type": "thought", "content": thought}

        if action == "search":
            query = decision.get("query")
            if not query:
                yield {"type": "error", "content": "âš ï¸ ç”Ÿæˆäº†ç©ºçš„æœç´¢è¯ï¼Œå°è¯•è·³è¿‡..."}
                continue

            # 2. æ¨é€åŠ¨ä½œ
            yield {"type": "action", "content": f"ğŸ” **æ‰§è¡Œæœç´¢**: `{query}`"}

            # 3. æ‰§è¡Œæœç´¢å·¥å…·
            tool_output = unified_search(query, source, bocha_k, google_k, google_c, proxy)

            # 4. æ¨é€å·¥å…·ç»“æœæ‘˜è¦
            yield {"type": "tool_output", "content": tool_output}

            # æ›´æ–°å¯¹è¯å†å²
            messages.append({"role": "assistant", "content": content})
            messages.append({"role": "user", "content": f"ã€æœç´¢å·¥å…·è¿”å›æ•°æ®ã€‘:\n{tool_output}"})

        elif action == "finish":
            final_answer = decision.get("answer")
            yield {"type": "final_answer", "content": final_answer}
            return

        else:
            yield {"type": "error", "content": f"âš ï¸ æœªçŸ¥åŠ¨ä½œ: {action}"}
            break

    yield {"type": "final_answer", "content": "ğŸ›‘ å·²è¾¾åˆ°æœ€å¤§æ­¥æ•°ï¼Œåœæ­¢æœç´¢ã€‚ä»¥ä¸‹æ˜¯åŸºäºç°æœ‰ä¿¡æ¯çš„æ€»ç»“ã€‚"}


# ================= [UI äº¤äº’é€»è¾‘] =================

# åˆå§‹åŒ– Session State
if "messages" not in st.session_state:
    st.session_state.messages = []

# 1. æ¸²æŸ“å†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        # å¦‚æœæœ‰è¯¦ç»†è¿‡ç¨‹æ—¥å¿—ï¼Œä½¿ç”¨æŠ˜å é¢æ¿æ˜¾ç¤º
        if "details" in msg and msg["details"]:
            with st.expander("ğŸ•µï¸ æŸ¥çœ‹æ·±åº¦æ€è€ƒä¸æœç´¢è¿‡ç¨‹"):
                st.markdown(msg["details"])

# 2. å¤„ç†ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œå¼€å§‹æ·±åº¦æœç´¢..."):
    # æ˜¾ç¤ºç”¨æˆ·æé—®
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # åŠ©æ‰‹å“åº”åŒº
    with st.chat_message("assistant"):
        # çŠ¶æ€å®¹å™¨ï¼šç”¨äºæ˜¾ç¤ºå®æ—¶çš„æ€è€ƒåŠ¨ç”»
        status_container = st.status("ğŸ§  å¤§è„‘å¯åŠ¨ä¸­...", expanded=True)
        final_answer_container = st.empty()

        # ç”¨äºè®°å½•å®Œæ•´çš„æ€è€ƒæ—¥å¿—ï¼Œä»¥ä¾¿å­˜å…¥å†å²
        process_log_markdown = ""

        # å¯åŠ¨ç”Ÿæˆå™¨
        gen = run_agent_generator(
            prompt, silicon_key, base_url, model_name,
            search_source_option, bocha_key, google_key, google_cx, proxy_url, max_steps
        )

        final_response = ""

        try:
            for event in gen:
                # --- çŠ¶æ€æ æ ‡é¢˜æ›´æ–° ---
                if event["type"] == "status_update":
                    status_container.update(label=event["content"], state="running")

                # --- æ€è€ƒè¿‡ç¨‹å±•ç¤º ---
                elif event["type"] == "thought":
                    # æ ¼å¼åŒ–ä¸€ä¸‹æ€è€ƒå†…å®¹ï¼ŒåŠ ç²—åˆ†æ®µ
                    formatted_thought = event['content'].replace('\n', '\n\n')
                    msg = f"#### ğŸ¤” æ·±åº¦æ€è€ƒ\n{formatted_thought}\n\n---\n"
                    status_container.markdown(msg)
                    process_log_markdown += msg

                # --- åŠ¨ä½œå±•ç¤º ---
                elif event["type"] == "action":
                    msg = f"{event['content']}\n\n"
                    status_container.markdown(msg)
                    process_log_markdown += msg

                # --- å·¥å…·ç»“æœå±•ç¤º ---
                elif event["type"] == "tool_output":
                    # æˆªå–å‰ 150 å­—ç¬¦åšé¢„è§ˆ
                    preview = event['content'][:1500].replace('\n', ' ') + "..."
                    status_container.caption(f"ğŸ“„ *å·²è·å–ç½‘é¡µå†…å®¹ (æ‘˜è¦)*: {preview}")
                    # æ—¥å¿—é‡Œè®°å½•è¾ƒè¯¦ç»†çš„å†…å®¹ï¼ˆä½†ä¸è‡³äºå¤ªé•¿ï¼‰
                    process_log_markdown += f"ğŸ“„ **ç½‘é¡µæŠ“å–ç»“æœ**: \n```text\n{event['content'][:1000]}...\n```\n\n---\n"

                # --- é”™è¯¯å¤„ç† ---
                elif event["type"] == "error":
                    status_container.error(event["content"])
                    process_log_markdown += f"âŒ **Error**: {event['content']}\n"

                # --- æœ€ç»ˆç­”æ¡ˆ ---
                elif event["type"] == "final_answer":
                    final_response = event["content"]
                    status_container.update(label="âœ… ä»»åŠ¡å®Œæˆ", state="complete", expanded=False)
                    final_answer_container.markdown(final_response)

        except Exception as e:
            st.error(f"ç¨‹åºè¿è¡Œå¼‚å¸¸: {e}")

        # å°†æœ€ç»ˆç»“æœä¿å­˜åˆ°å†å²
        if final_response:
            st.session_state.messages.append({
                "role": "assistant",
                "content": final_response,
                "details": process_log_markdown
            })